[package]
name = "bitnet-inference"
version = "0.1.0"
edition.workspace = true
authors.workspace = true
license.workspace = true
repository.workspace = true
homepage.workspace = true
documentation.workspace = true
description = "High-performance inference engine for BitNet models"
keywords = ["bitnet", "inference", "neural-networks", "text-generation"]
categories = ["science"]

[features]
default = ["std", "tokenizers"]
std = []
# Enable tokenization
tokenizers = ["dep:tokenizers"]
# Enable text generation utilities
generation = ["dep:rand"]
# Enable batch processing
batching = ["dep:rayon"]
# Enable streaming inference
streaming = ["dep:tokio"]
# Enable Metal acceleration (temporarily disabled due to dependency issues)
# metal = ["dep:bitnet-metal"]

[dependencies]
bitnet-core = { path = "../bitnet-core", version = ">=0.1.0, <0.3.0" }
bitnet-quant = { path = "../bitnet-quant", version = ">=0.1.0, <0.3.0" }
# bitnet-metal = { path = "../bitnet-metal", version = "0.1.0", optional = true }

# Core dependencies
candle-core.workspace = true
serde.workspace = true
anyhow.workspace = true
thiserror.workspace = true

# Tokenization
tokenizers = { workspace = true, optional = true }

# Text generation
rand = { version = "0.8", optional = true }

# Performance
rayon = { workspace = true, optional = true }
tokio = { workspace = true, optional = true }

# Utilities
tracing = { workspace = true, optional = true }
uuid = "1.0"

[dev-dependencies]
criterion.workspace = true
proptest.workspace = true
tokio = { workspace = true, features = ["test-util"] }
